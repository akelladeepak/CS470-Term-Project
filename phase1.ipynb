{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5a4fac",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcf92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "def read_arff_file(filepath, dimension_name):\n",
    "    \"\"\"\n",
    "    Reads an ARFF file, converts the data to a DataFrame, and \n",
    "    renames the columns as '[dimension_name]_t1', '[dimension_name]_t2', etc.\n",
    "    \"\"\"\n",
    "    data, meta = arff.loadarff(filepath)\n",
    "    df = pd.DataFrame(data)\n",
    "    num_columns = df.shape[1]\n",
    "    df.columns = [f\"{dimension_name}_t{i+1}\" for i in range(num_columns)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938dafbc",
   "metadata": {},
   "source": [
    "# Creating the Table (Using Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c62c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_folder(folder_path, dataset_name):\n",
    "    \"\"\"\n",
    "    Processes one dataset folder by reading ARFF files and combining \n",
    "    them into a single table, preserving train/test splits and adding 'sid'.\n",
    "    \"\"\"\n",
    "    arff_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.arff')]\n",
    "    train_dfs, test_dfs = [], []\n",
    "\n",
    "    for file in arff_files:\n",
    "        split = 'train' if 'TRAIN' in file.upper() else 'test' if 'TEST' in file.upper() else None\n",
    "        if not split:\n",
    "            print(f\"Warning: couldn't mark split for {file}\")\n",
    "            continue\n",
    "\n",
    "        base = os.path.splitext(file)[0]\n",
    "        # strip the suffix, keep everything before '_TRAIN' or '_TEST'\n",
    "        dimension = base.replace('_TRAIN', '').replace('_TEST', '')\n",
    "        \n",
    "        df_dim = read_arff_file(os.path.join(folder_path, file), dimension.title())\n",
    "        df_dim['split'] = split\n",
    "\n",
    "        (train_dfs if split == 'train' else test_dfs).append(df_dim)\n",
    "\n",
    "    def concat_and_sid(dfs):\n",
    "        if not dfs:\n",
    "            return pd.DataFrame()\n",
    "        df = pd.concat(dfs, axis=1)\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "        df.insert(0, 'sid', range(1, len(df) + 1))\n",
    "        return df\n",
    "\n",
    "    df_train = concat_and_sid(train_dfs)\n",
    "    df_test  = concat_and_sid(test_dfs)\n",
    "    df_all   = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    df_all['dataset'] = dataset_name\n",
    "    return df_all\n",
    "\n",
    "def create_final_table():\n",
    "    base = 'Phase1_Data'\n",
    "    natops_folder = os.path.join(base, 'NATOPS')\n",
    "    if not os.path.isdir(natops_folder):\n",
    "        raise FileNotFoundError(f\"NATOPS folder not found at {natops_folder}\")\n",
    "    return process_dataset_folder(natops_folder, 'NATOPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a84f03",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba793745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined NATOPS data to Phase1_NATOPS_Combined.csv\n",
      "First 5 rows:\n",
      "   sid  Natopsdimension10_t1  Natopsdimension10_t2  Natopsdimension10_t3  \\\n",
      "0    1              0.599967              0.597535              0.597007   \n",
      "1    2              0.622368              0.622228              0.622004   \n",
      "2    3              0.588525              0.588389              0.588164   \n",
      "3    4              0.576847              0.576713              0.575015   \n",
      "4    5              0.717469              0.722515              0.725107   \n",
      "\n",
      "   Natopsdimension10_t4  Natopsdimension10_t5  Natopsdimension10_t6  \\\n",
      "0              0.599099              0.606181              0.620752   \n",
      "1              0.621909              0.621940              0.622165   \n",
      "2              0.588034              0.587961              0.587895   \n",
      "3              0.575267              0.572163              0.555767   \n",
      "4              0.726653              0.709988              0.712092   \n",
      "\n",
      "   Natopsdimension10_t7  Natopsdimension10_t8  Natopsdimension10_t9  ...  \\\n",
      "0              0.630438              0.631059              0.628942  ...   \n",
      "1              0.622169              0.622187              0.622277  ...   \n",
      "2              0.591413              0.605781              0.679733  ...   \n",
      "3              0.555370              0.603450              0.669051  ...   \n",
      "4              0.718585              0.732054              0.739200  ...   \n",
      "\n",
      "   Natopsdimension9_t46  Natopsdimension9_t47  Natopsdimension9_t48  \\\n",
      "0             -0.151265             -0.149752             -0.163843   \n",
      "1             -0.173544             -0.167847             -0.159090   \n",
      "2             -0.161653             -0.163661             -0.163518   \n",
      "3             -0.155229             -0.148243             -0.148955   \n",
      "4             -0.273925             -0.271116             -0.272523   \n",
      "\n",
      "   Natopsdimension9_t49  Natopsdimension9_t50  Natopsdimension9_t51  \\\n",
      "0             -0.167192             -0.149480             -0.152398   \n",
      "1             -0.156384             -0.154926             -0.153674   \n",
      "2             -0.163756             -0.164298             -0.165037   \n",
      "3             -0.150318             -0.147396             -0.150914   \n",
      "4             -0.271146             -0.270345             -0.273293   \n",
      "\n",
      "   Natopsdimension9_t52                                          Natops_t1  \\\n",
      "0                b'4.0'  [[-0.372758, -0.367844, -0.378445, -0.386751, ...   \n",
      "1                b'3.0'  [[-0.54737, -0.546334, -0.549748, -0.546891, -...   \n",
      "2                b'3.0'  [[-0.587062, -0.587322, -0.586417, -0.584654, ...   \n",
      "3                b'4.0'  [[-0.514671, -0.51864, -0.521285, -0.522843, -...   \n",
      "4                b'3.0'  [[-0.718601, -0.721093, -0.717955, -0.722386, ...   \n",
      "\n",
      "   Natops_t2  dataset  \n",
      "0     b'4.0'   NATOPS  \n",
      "1     b'3.0'   NATOPS  \n",
      "2     b'3.0'   NATOPS  \n",
      "3     b'4.0'   NATOPS  \n",
      "4     b'3.0'   NATOPS  \n",
      "\n",
      "[5 rows x 1253 columns]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    final_table = create_final_table()\n",
    "    out_csv = 'Phase1_NATOPS_Combined.csv'\n",
    "    final_table.to_csv(out_csv, index=False)\n",
    "    print(f\"Saved combined NATOPS data to {out_csv}\")\n",
    "    print(\"First 5 rows:\")\n",
    "    print(final_table.head(5))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
