{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5a4fac",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdcf92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "def read_arff_file(filepath, dimension_name):\n",
    "    \"\"\"\n",
    "    - Loads an ARFF into a DataFrame.\n",
    "    - Decodes any byte-strings to UTF-8 str.\n",
    "    - Attempts to cast numeric columns.\n",
    "    - Prefixes everything except 'class' with '{dimension_name}_'.\n",
    "    \"\"\"\n",
    "    raw_data, _ = arff.loadarff(filepath)\n",
    "    df = pd.DataFrame(raw_data)\n",
    "\n",
    "    # Decode bytes → str\n",
    "    for col in df.select_dtypes([object]):\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: x.decode('utf-8') if isinstance(x, bytes) else x\n",
    "        )\n",
    "\n",
    "    # Numeric cast\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except (ValueError, TypeError):\n",
    "            pass\n",
    "\n",
    "    # Rename\n",
    "    df.columns = [\n",
    "        'class' if col == 'class' else f\"{dimension_name}_{col}\"\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938dafbc",
   "metadata": {},
   "source": [
    "# Phase 1: Combine NATOPS ARFF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12c62c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_and_sid(dfs):\n",
    "    \"\"\"\n",
    "    - Horizontally concat a list of DataFrames (one per dimension).\n",
    "    - Drop any duplicated columns.\n",
    "    - Insert a 1-based 'sid'.\n",
    "    \"\"\"\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    df.insert(0, 'sid', range(1, len(df) + 1))\n",
    "    return df\n",
    "\n",
    "def process_dataset_folder(folder_path, dataset_name):\n",
    "    \"\"\"\n",
    "    - Reads all .arff in folder_path.\n",
    "    - Splits them into train/test by filename.\n",
    "    - Builds a wide table per split, adds sid, then stacks train+test.\n",
    "    - Tags with a `dataset` column.\n",
    "    \"\"\"\n",
    "    arff_files = [\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith('.arff')\n",
    "    ]\n",
    "    train_dfs, test_dfs = [], []\n",
    "\n",
    "    for fn in arff_files:\n",
    "        name_upper = fn.upper()\n",
    "        if 'TRAIN' in name_upper:\n",
    "            split = 'train'\n",
    "        elif 'TEST' in name_upper:\n",
    "            split = 'test'\n",
    "        else:\n",
    "            print(f\"⚠️  Skipping unrecognized file: {fn}\")\n",
    "            continue\n",
    "\n",
    "        base = os.path.splitext(fn)[0]\n",
    "        dimension = base.upper().replace('_TRAIN','').replace('_TEST','').lower()\n",
    "        df_dim = read_arff_file(os.path.join(folder_path, fn), dimension)\n",
    "        df_dim['split'] = split\n",
    "\n",
    "        if split == 'train':\n",
    "            train_dfs.append(df_dim)\n",
    "        else:\n",
    "            test_dfs.append(df_dim)\n",
    "\n",
    "    df_train = concat_and_sid(train_dfs)\n",
    "    df_test  = concat_and_sid(test_dfs)\n",
    "    df_all   = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "    # Quick sanity check\n",
    "    feature_cols = [\n",
    "        c for c in df_all.columns\n",
    "        if c not in ('sid','split','class')\n",
    "    ]\n",
    "    if not feature_cols:\n",
    "        raise RuntimeError(\"No feature columns found in wide DataFrame. \"\n",
    "                           \"Check that your .arff files were read correctly.\")\n",
    "    df_all['dataset'] = dataset_name\n",
    "    return df_all\n",
    "\n",
    "def melt_to_time_steps(df):\n",
    "    \"\"\"\n",
    "    Turn the wide table (one row per sid) into long form:\n",
    "      - one row per (sid, time_step)\n",
    "      - columns: sid, split, class, time_step, plus one column per dimension\n",
    "    \"\"\"\n",
    "    id_vars = [c for c in ('sid','split','class') if c in df.columns]\n",
    "\n",
    "    # all dimension prefixes (anything before the first '_', excluding id_vars+dataset)\n",
    "    dims = sorted({\n",
    "        col.split('_')[0]\n",
    "        for col in df.columns\n",
    "        if '_' in col and col.split('_')[0] not in id_vars + ['dataset']\n",
    "    })\n",
    "\n",
    "    if not dims:\n",
    "        raise RuntimeError(\"No dimensions detected—nothing to melt.\")\n",
    "\n",
    "    melted_dfs = []\n",
    "    for dim in dims:\n",
    "        prefix = f\"{dim}_\"\n",
    "        # pick up every column that starts with e.g. \"acceleration_\"\n",
    "        time_cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "        if not time_cols:\n",
    "            # maybe no numeric/time cols for this dim\n",
    "            continue\n",
    "\n",
    "        # stable sort by suffix, attempting numeric if possible\n",
    "        def sort_key(c):\n",
    "            suf = c[len(prefix):]\n",
    "            return int(suf) if suf.isdigit() else suf\n",
    "\n",
    "        time_cols = sorted(time_cols, key=sort_key)\n",
    "\n",
    "        # melt that dimension out\n",
    "        m = df[id_vars + time_cols].melt(\n",
    "            id_vars=id_vars,\n",
    "            value_vars=time_cols,\n",
    "            var_name='time',\n",
    "            value_name=dim\n",
    "        )\n",
    "        # extract a time_step index (0-based)\n",
    "        m['time_step'] = m['time'].map({col: i\n",
    "                                         for i, col in enumerate(time_cols)})\n",
    "        m = m.drop(columns='time')\n",
    "        melted_dfs.append(m)\n",
    "\n",
    "    if not melted_dfs:\n",
    "        raise RuntimeError(\"After filtering, no dimension had time-step columns.\")\n",
    "\n",
    "    # now merge them one by one on sid/split/class/time_step\n",
    "    df_long = melted_dfs[0]\n",
    "    for df_next in melted_dfs[1:]:\n",
    "        df_long = pd.merge(\n",
    "            df_long, df_next,\n",
    "            on=id_vars + ['time_step']\n",
    "        )\n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be54f661",
   "metadata": {},
   "source": [
    "# Phase 2: Clustering & Atomic-Unit Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25084f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(df, feature_cols, n_clusters, random_state=42):\n",
    "    \"\"\"\n",
    "    Runs KMeans on the numeric subset of feature_cols,\n",
    "    writes the cluster label into df['cluster'], and returns df.\n",
    "    \"\"\"\n",
    "    numeric = [c for c in feature_cols\n",
    "               if np.issubdtype(df[c].dtype, np.number)]\n",
    "    dropped = set(feature_cols) - set(numeric)\n",
    "    if dropped:\n",
    "        print(f\"⚠️  Dropped non-numeric before clustering: {dropped}\")\n",
    "\n",
    "    X = df[numeric].to_numpy()\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
    "    df['cluster'] = km.fit_predict(X)\n",
    "    return df\n",
    "\n",
    "def compute_ratio_features(df, n_clusters):\n",
    "    \"\"\"\n",
    "    For each (split, sid, class) group, compute the normalized\n",
    "    counts of each cluster → cluster_i_ratio features.\n",
    "    \"\"\"\n",
    "    group_cols = [c for c in ('split','sid','class') if c in df.columns]\n",
    "    ratios = (\n",
    "        df\n",
    "        .groupby(group_cols)['cluster']\n",
    "        .value_counts(normalize=True)\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "    ratios.columns = [f\"cluster_{int(c)}_ratio\"\n",
    "                      for c in ratios.columns]\n",
    "    return ratios.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a84f03",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba793745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Phase 1 (wide) sample:\n",
      "   sid  natopsdimension10_channel_9_0  natopsdimension10_channel_9_1  \\\n",
      "0    1                       0.599967                       0.597535   \n",
      "1    2                       0.622368                       0.622228   \n",
      "2    3                       0.588525                       0.588389   \n",
      "3    4                       0.576847                       0.576713   \n",
      "4    5                       0.717469                       0.722515   \n",
      "\n",
      "   natopsdimension10_channel_9_2  natopsdimension10_channel_9_3  \\\n",
      "0                       0.597007                       0.599099   \n",
      "1                       0.622004                       0.621909   \n",
      "2                       0.588164                       0.588034   \n",
      "3                       0.575015                       0.575267   \n",
      "4                       0.725107                       0.726653   \n",
      "\n",
      "   natopsdimension10_channel_9_4  natopsdimension10_channel_9_5  \\\n",
      "0                       0.606181                       0.620752   \n",
      "1                       0.621940                       0.622165   \n",
      "2                       0.587961                       0.587895   \n",
      "3                       0.572163                       0.555767   \n",
      "4                       0.709988                       0.712092   \n",
      "\n",
      "   natopsdimension10_channel_9_6  natopsdimension10_channel_9_7  \\\n",
      "0                       0.630438                       0.631059   \n",
      "1                       0.622169                       0.622187   \n",
      "2                       0.591413                       0.605781   \n",
      "3                       0.555370                       0.603450   \n",
      "4                       0.718585                       0.732054   \n",
      "\n",
      "   natopsdimension10_channel_9_8  ...  natopsdimension9_channel_8_45  \\\n",
      "0                       0.628942  ...                      -0.151265   \n",
      "1                       0.622277  ...                      -0.173544   \n",
      "2                       0.679733  ...                      -0.161653   \n",
      "3                       0.669051  ...                      -0.155229   \n",
      "4                       0.739200  ...                      -0.273925   \n",
      "\n",
      "   natopsdimension9_channel_8_46  natopsdimension9_channel_8_47  \\\n",
      "0                      -0.149752                      -0.163843   \n",
      "1                      -0.167847                      -0.159090   \n",
      "2                      -0.163661                      -0.163518   \n",
      "3                      -0.148243                      -0.148955   \n",
      "4                      -0.271116                      -0.272523   \n",
      "\n",
      "   natopsdimension9_channel_8_48  natopsdimension9_channel_8_49  \\\n",
      "0                      -0.167192                      -0.149480   \n",
      "1                      -0.156384                      -0.154926   \n",
      "2                      -0.163756                      -0.164298   \n",
      "3                      -0.150318                      -0.147396   \n",
      "4                      -0.271146                      -0.270345   \n",
      "\n",
      "   natopsdimension9_channel_8_50  natopsdimension9_classAttribute  \\\n",
      "0                      -0.152398                              4.0   \n",
      "1                      -0.153674                              3.0   \n",
      "2                      -0.165037                              3.0   \n",
      "3                      -0.150914                              4.0   \n",
      "4                      -0.273293                              3.0   \n",
      "\n",
      "                                natops_relationalAtt  natops_classAttribute  \\\n",
      "0  [[-0.372758, -0.367844, -0.378445, -0.386751, ...                    4.0   \n",
      "1  [[-0.54737, -0.546334, -0.549748, -0.546891, -...                    3.0   \n",
      "2  [[-0.587062, -0.587322, -0.586417, -0.584654, ...                    3.0   \n",
      "3  [[-0.514671, -0.51864, -0.521285, -0.522843, -...                    4.0   \n",
      "4  [[-0.718601, -0.721093, -0.717955, -0.722386, ...                    3.0   \n",
      "\n",
      "   dataset  \n",
      "0   NATOPS  \n",
      "1   NATOPS  \n",
      "2   NATOPS  \n",
      "3   NATOPS  \n",
      "4   NATOPS  \n",
      "\n",
      "[5 rows x 1253 columns] \n",
      "\n",
      "▶️ Phase 1 (long) sample:\n",
      "   sid  split natops  time_step  natopsdimension1  natopsdimension10  \\\n",
      "0    1  train    4.0          0         -0.372758           0.599967   \n",
      "1    2  train    3.0          0         -0.547370           0.622368   \n",
      "2    3  train    3.0          0         -0.587062           0.588525   \n",
      "3    4  train    4.0          0         -0.514671           0.576847   \n",
      "4    5  train    3.0          0         -0.718601           0.717469   \n",
      "\n",
      "   natopsdimension11  natopsdimension12  natopsdimension13  natopsdimension14  \\\n",
      "0          -0.823936          -0.286140          -0.507478          -1.369001   \n",
      "1          -0.717765          -0.095969          -0.649392          -1.250653   \n",
      "2          -0.813381          -0.073817          -0.680587          -1.349298   \n",
      "3          -0.769109          -0.276138          -0.528208          -1.502747   \n",
      "4          -0.898846          -0.160594          -0.668832          -1.721710   \n",
      "\n",
      "   ...  natopsdimension22  natopsdimension23  natopsdimension24  \\\n",
      "0  ...           0.619205          -1.771773          -0.810086   \n",
      "1  ...           0.618919          -1.497652          -0.754927   \n",
      "2  ...           0.417640          -1.549212          -0.564249   \n",
      "3  ...           0.439658          -1.701396          -0.809376   \n",
      "4  ...           0.634141          -1.956089          -0.797694   \n",
      "\n",
      "   natopsdimension3  natopsdimension4  natopsdimension5  natopsdimension6  \\\n",
      "0         -0.846321          0.465208         -2.015072         -0.839242   \n",
      "1         -0.809446          0.556062         -1.669622         -0.748726   \n",
      "2         -0.648786          0.542660         -1.759520         -0.573142   \n",
      "3         -0.748957          0.571942         -1.988466         -0.745504   \n",
      "4         -0.859093          0.808480         -2.175653         -0.763930   \n",
      "\n",
      "   natopsdimension7  natopsdimension8  natopsdimension9  \n",
      "0         -0.564097         -0.796225         -0.149604  \n",
      "1         -0.668990         -0.673415         -0.162021  \n",
      "2         -0.683921         -0.750000         -0.146066  \n",
      "3         -0.563803         -0.729743         -0.132236  \n",
      "4         -0.689536         -0.803106         -0.269982  \n",
      "\n",
      "[5 rows x 28 columns] \n",
      "\n",
      "⚠️  Dropped non-numeric before clustering: {'natops'}\n",
      "▶️ Phase 2 sample:\n",
      "  split  sid  cluster_0_ratio  cluster_1_ratio  cluster_2_ratio  \\\n",
      "0  test    1              0.0              1.0              0.0   \n",
      "1  test    2              0.0              1.0              0.0   \n",
      "2  test    3              0.0              0.0              0.0   \n",
      "3  test    4              0.0              1.0              0.0   \n",
      "4  test    5              0.0              0.0              0.0   \n",
      "\n",
      "   cluster_3_ratio  cluster_4_ratio  cluster_5_ratio  cluster_6_ratio  \\\n",
      "0              0.0              0.0              0.0              0.0   \n",
      "1              0.0              0.0              0.0              0.0   \n",
      "2              0.0              1.0              0.0              0.0   \n",
      "3              0.0              0.0              0.0              0.0   \n",
      "4              0.0              1.0              0.0              0.0   \n",
      "\n",
      "   cluster_7_ratio  cluster_8_ratio  cluster_9_ratio  \n",
      "0              0.0              0.0              0.0  \n",
      "1              0.0              0.0              0.0  \n",
      "2              0.0              0.0              0.0  \n",
      "3              0.0              0.0              0.0  \n",
      "4              0.0              0.0              0.0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Phase 1: ingest wide\n",
    "    base_folder = os.path.join('Phase1_Data','NATOPS')\n",
    "    if not os.path.isdir(base_folder):\n",
    "        raise FileNotFoundError(f\"NATOPS folder not found at {base_folder}\")\n",
    "\n",
    "    df_wide = process_dataset_folder(base_folder, 'NATOPS')\n",
    "    print(\"▶️ Phase 1 (wide) sample:\")\n",
    "    print(df_wide.head(), \"\\n\")\n",
    "    df_wide.to_csv('Phase1_NATOPS_Combined_wide.csv', index=False)\n",
    "\n",
    "    # Phase 1: reshape to long\n",
    "    df_long = melt_to_time_steps(df_wide)\n",
    "    print(\"▶️ Phase 1 (long) sample:\")\n",
    "    print(df_long.head(), \"\\n\")\n",
    "    df_long.to_csv('Phase1_NATOPS_Combined_long.csv', index=False)\n",
    "\n",
    "    # Phase 2: clustering & ratio features\n",
    "    n_clusters = 10\n",
    "    feat_cols = [c for c in df_long.columns\n",
    "                 if c not in ('sid','split','class','time_step')]\n",
    "    df_clust = perform_clustering(df_long.copy(), feat_cols, n_clusters)\n",
    "    df_phase2 = compute_ratio_features(df_clust, n_clusters)\n",
    "\n",
    "    print(\"▶️ Phase 2 sample:\")\n",
    "    print(df_phase2.head(), \"\\n\")\n",
    "    df_phase2.to_csv('Phase2_NATOPS_AtomicUnits.csv', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
